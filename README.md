<div align="center">
<h1>Awesome Remote Sensing Image Captioning</h1>
</div>

This repository contains a collection of resources, codes and papers on Remote Sensing Image Captioning.

To add your work to this repo, feel free to submit the request or contact me at liuchenyang@buaa.edu.cn

[//]: # (### Datasets)

[//]: # (| Dataset info | Description |)

[//]: # (|---|---|)

[//]: # (| [NWPU-Captions]&#40;https://ieeexplore.ieee.org/document/9866055/&#41;<br/>> Huazhong University of Science and Technology<br/> >English<br/>> 2022<br/>> 45 categories<br/>> 31500 images<br/>> 30 m - 0.2 m | <div align="center"><img src="assets/NWPU-Captions.jpg" width="300"></div><br/>The NWPU-Captions dataset is a larger and more challenging benchmark dataset for remote sensing image captioning, containing 157,500 manually annotated sentences and 31,500 images, offering a greater data volume, category variety, description richness, and wider coverage of complex scenes and vocabulary. |)

[//]: # (| [RSICD]&#40;https://ieeexplore.ieee.org/document/8240966&#41;<br/>> University of Chinese Academy of Sciences<br/> >English<br/>> 2018<br/>> 30 categories<br/>> 10921 images | <div align="center"><img src="https://ieeexplore.ieee.org/mediastore_new/IEEE/content/media/36/8323433/8240966/lu1-2776321-large.gif" width="300"></div><br/>It contains more than ten thousands remote sensing images which are collected from Google Earth, Baidu Map, MapABC and Tianditu. |)

[//]: # (| [Sydney captions]&#40;https://ieeexplore.ieee.org/document/7546397&#41;<br/>> University of the Chinese Academy of Sciences<br/> >English<br/>> 2016<br/>> 7 categories<br/>> 613 images<br/>> 0.5m | <div align="center"><img src="https://ieeexplore.ieee.org/mediastore_new/IEEE/content/media/7536293/7546377/7546397/7546397-fig-4-source-large.gif" width="300"></div><br/>It contains 7 different scene categories and totally has 613 HSR images. |)

[//]: # (| [UCM captions]&#40;https://ieeexplore.ieee.org/document/7546397&#41;<br/>> University of the Chinese Academy of Sciences<br/> >English<br/>> 2016<br/>> 21 categories<br/>> 2100 images<br/>> 0.3048m | <div align="center"><img src="https://ieeexplore.ieee.org/mediastore_new/IEEE/content/media/7536293/7546377/7546397/7546397-fig-4-source-large.gif" width="300"></div><br/>It is based on the UC Merced Land Use Dataset and has  2100 HSR images which are divided into 21 challenging scene categories. |)


### Papers
| Publication     | Paper                                                                                                                                                     | Code Repository                                                                                                            |
|-----------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------|
| **GRSL 2022**   | [Remote Sensing Image Captioning Based on Multi-Layer Aggregated Transformer](https://ieeexplore.ieee.org/document/9709791) *Liu et al.*                  | [MLAT](https://github.com/Chen-Yang-Liu/MLAT)                                                                              
| **TGRS 2022**   | [High-Resolution Remote Sensing Image Captioning Based on Structured Attention](https://ieeexplore.ieee.org/document/9400386) *Zhao et al.*               |                                                                                                                            |
| **TGRS 2022**   | [A Novel SVM-Based Decoder for Remote Sensing Image Captioning](https://ieeexplore.ieee.org/document/9521989) *Hoxha et al.*                              |                                                                                                                            |
| **IGARSS 2022** | [Capformer: Pure Transformer for Remote Sensing Image Caption](https://ieeexplore.ieee.org/document/9883199) *Wang et al.* | [Capformer](https://github.com/Junjue-Wang/CapFormer)                                                                      
| **TGRS 2022**   | [Word-Sentence Framework for Remote Sensing Image Captioning](https://ieeexplore.ieee.org/document/9308980) *Wang et al.* | [[code]](https://github.com/hw2hwei/WordSent)
| **RS   2022**   | [A Mask-Guided Transformer Network with Topic Token for Remote Sensing Image Captioning](https://www.mdpi.com/2072-4292/14/12/2939) *Ren et al.* | [[code]](https://github.com/Meditation0119/a-mask-guided-transformer-with-topic-token-for-remote-sensing-image-captioning) 
| **GRSL 2022**   | [Exploring Transformer and multi-label classification for remote sensing image captioning](https://ieeexplore.ieee.org/document/9855519) *Kandala et al.* | [[code]](https://github.com/hiteshK03/Remote-sensing-image-captioning-with-transformer-and-multilabel-classification)      
| **TGRS 2021**   | [SD-RSIC: Summarization-Driven Deep Remote Sensing Image Captioning](https://ieeexplore.ieee.org/document/9239371) *Sumbull et al.*                       | [[code]](https://git.tu-berlin.de/rsim/SD-RSIC)<br/>                                                                       
| **TGRS 2017**   | [Exploring Models and Data for Remote Sensing Image Caption Generation](https://ieeexplore.ieee.org/document/8240966) *Lu et al.*                         |
| **TGRS 2017**   | [Can a Machine Generate Humanlike Language Descriptions for a Remote Sensing Image?](https://ieeexplore.ieee.org/document/7891049) *Shi et al.*           |
| **CITS 2016**   | [Deep semantic understanding of high resolution remote sensing image](https://ieeexplore.ieee.org/abstract/document/7546397) *Qu et al.*                  |

